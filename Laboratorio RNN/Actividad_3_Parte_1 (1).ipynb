{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "# Primera parte: Clasificación de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "En esta parte, utilizaremos **embeddings** para resolver un problema de clasificación de texto. Los embeddings, representaciones distribuidas y vectoriales de elementos, son un concepto muy común en el mundo del deep learning. Los **word vectors** que hemos visto en clase son una representación en forma de embedding de las palabras.\n",
    "\n",
    "Para realizar este trabajo y sacarle el máximo partido, se recomienda ver los siguientes vídeos de clase:\n",
    "\n",
    "*   Clasificación de texto con Word Vectors.\n",
    "*   Análisis de overfitting con un modelo bag of words.\n",
    "*   Clasificación de texto con RNN\n",
    "\n",
    "Vamos a utilizar el dataset **\"Reuters newswire topics classification\"**, disponible desde Keras de manera similar al dataset de IMDB ([ver documentación](https://keras.io/datasets/#reuters-newswire-topics-classification)).\n",
    "\n",
    "---\n",
    "\n",
    "Se pide:\n",
    "\n",
    "Entrenar un modelo **utilizando embeddings** que consiga un **65% de accuracy en test (55% si usamos RNNs)**, mostrando el entrenamiento y el resultado final.\n",
    " \n",
    "Tenemos varias opciones para entrenar modelos con embeddings. El alumno puede explorar más de una pero es suficiente con conseguir un modelo que alcance la accuracy requerida:\n",
    "\n",
    "*   Utilizar una **media de embeddings** al estilo de lo visto en el vídeo *Clasificación de texto con Word Vectors*\n",
    "*   Utilizar una **CNN** sobre una secuencia de word vectors. Aquí necesitamos cambiar un poco la idea de convolución para actuar sobre sequencias de vectores. Keras incluye una [Convolución en 1D](https://keras.io/layers/convolutional/#conv1d) que puede ser utilizada en este caso, con un ejemplo de uso en la documentación. Una forma de hacer funcionar este esquema sería utilizar la convolución en 1D + max pooling.\n",
    "*  Utilizar una **RNN** sobre una secuencia de word vectors, al estilo de lo visto en el vídeo *Clasificación de texto con RNN*. Para este problema es un poco complicado conseguir un buen modelo con RNNs, y además es más difícil experimentar ya que las redes recurrentes son modelos lentos de entrenar. Por eso, es suficiente con alcanzar un 55% de accuracy si optamos por utilizar un modelo de este estilo. Un buen consejo es emplear una red recurrente bidireccional como se ve en el vídeo *Clasificación de texto con RNN*.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Dos hiperparámetros importantes a elegir en el modelo son la **longitud de las secuencias de texto** y el **tamaño del vocabulario** para los embeddings. Podéis experimentar con ambos, o utilizar los mismos que se usan en los vídeos. Nótese que, al cortar todas las secuencias para que tengan el mismo tamaño, podríamos estar perdiendo mucho texto si elegimos un tamaño de secuencia demasiado pequeño. Igualmente, si las hacemos muy largas necesitaremos más tiempo para entrenar nuestros modelos. Una buena idea consiste en explorar los datos para ver cómo suelen ser de largos los textos y encontrar un buen trade-off para el tamaño de al secuencia.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Los embeddings que hemos visto en los vídeos se entrenan junto al modelo.  Una técnica frecuente es inicializar estos embeddings con word-vectors pre-entrenados en un gran corpus de texto, como hemos visto en clase. Esto puede ayudar ya que nuestro modelo empieza con unos embeddings que ya encapsulan significado. Si bien no es necesario para esta práctica, podéis ver cómo usar esta técnica [en el siguiente tutorial](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "## Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Bidirectional, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100 #Crea arreglos de máximo este largo\n",
    "batch_size = 10\n",
    "max_features = 10000 #corta a este número de palabras más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos el conjunto de train y de test\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words = max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de tamaños de conjuntos de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 8982, labels: 8982\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(x_train), len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisión de cuántos elementos o categorías tiene el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indica la cantidad de categorías de clasificación, irían de 0 -- 45\n",
    "\n",
    "Por lo tanto se cuenta con 46 capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario hacer una codificación one hot a las categorías de 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elementos sin codificar: 3   3\n",
      "Elementos codificados: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]   [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Elementos sin codificar:\",y_train[0],' ', y_test[5])\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(\"Elementos codificados:\",y_train[0],' ', y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0]), len(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dictionary mapping words to an integer index\n",
    "word_index = reuters.get_word_index()\n",
    "\n",
    "#The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2 #Unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "  return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely <UNK> borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in <UNK> financial eligibility standards indicated as many as one half of <UNK> borrowers who received new loans from the agency in 1986 would be <UNK> under the proposed system the agency has proposed evaluating <UNK> credit using a variety of financial ratios instead of relying solely on <UNK> ability senate agriculture committee chairman patrick leahy d vt <UNK> the proposed eligibility changes telling <UNK> administrator <UNK> clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to <UNK> its 70 billion dlr loan portfolio in a <UNK> yet <UNK> manner crowley of gao <UNK> <UNK> arm said the proposed credit <UNK> system attempted to ensure that <UNK> would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agregan los PAD a la data de test y de entrenamiento\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobación de tamaños y contenido de los conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    2    2    8   43   10  447    5   25  207  270    5 3095  111\n",
      "   16  369  186   90   67    7   89    5   19  102    6   19  124   15\n",
      "   90   67   84   22  482   26    7   48    4   49    8  864   39  209\n",
      "  154    6  151    6   83   11   15   22  155   11   15    7   48    9\n",
      " 4579 1005  504    6  258    6  272   11   15   22  134   44   11   15\n",
      "   16    8  197 1245   90   67   52   29  209   30   32  132    6  109\n",
      "   15   17   12    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:4000]\n",
    "partial_x_train = train_data[4000:]\n",
    "\n",
    "y_val = y_train[:4000]\n",
    "partial_y_train = y_train[4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                782       \n",
      "=================================================================\n",
      "Total params: 160,782\n",
      "Trainable params: 160,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creación del modelo de embeddings con capa de dropout para regularizar la red\n",
    "#Y una capa de average pooling para simplificar los modelos de embedding utilizados\n",
    "vocab_size = max_features\n",
    "\n",
    "model_embed = Sequential()\n",
    "model_embed.add(Embedding(vocab_size, 16))\n",
    "model_embed.add(Dropout(0.2))\n",
    "model_embed.add(GlobalAveragePooling1D())\n",
    "model_embed.add(Dense(46, activation=tf.nn.sigmoid))\n",
    "#Se utilizan 46 capas de activación por la cantidad de categorías del dataset\n",
    "\n",
    "model_embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utiliza una métrica de pérdida de categorical crossentropy\n",
    "#Esto por la cantidad de categorías que tiene el dataset\n",
    "model_embed.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4982)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val), len(partial_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\NWUSER\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4982 samples, validate on 4000 samples\n",
      "Epoch 1/40\n",
      "4982/4982 [==============================] - 2s 357us/step - loss: 3.2191 - accuracy: 0.2547 - val_loss: 2.5715 - val_accuracy: 0.2122\n",
      "Epoch 2/40\n",
      "4982/4982 [==============================] - 1s 172us/step - loss: 2.3206 - accuracy: 0.4049 - val_loss: 2.2813 - val_accuracy: 0.4367\n",
      "Epoch 3/40\n",
      "4982/4982 [==============================] - 1s 165us/step - loss: 2.1872 - accuracy: 0.4289 - val_loss: 2.2185 - val_accuracy: 0.4173\n",
      "Epoch 4/40\n",
      "4982/4982 [==============================] - 1s 174us/step - loss: 2.0769 - accuracy: 0.3864 - val_loss: 2.0566 - val_accuracy: 0.4162\n",
      "Epoch 5/40\n",
      "4982/4982 [==============================] - 1s 176us/step - loss: 1.9321 - accuracy: 0.4398 - val_loss: 1.9675 - val_accuracy: 0.4415\n",
      "Epoch 6/40\n",
      "4982/4982 [==============================] - 1s 182us/step - loss: 1.8533 - accuracy: 0.4613 - val_loss: 1.9074 - val_accuracy: 0.4625\n",
      "Epoch 7/40\n",
      "4982/4982 [==============================] - 1s 168us/step - loss: 1.7903 - accuracy: 0.4809 - val_loss: 1.8561 - val_accuracy: 0.4793\n",
      "Epoch 8/40\n",
      "4982/4982 [==============================] - 1s 167us/step - loss: 1.7305 - accuracy: 0.4980 - val_loss: 1.8047 - val_accuracy: 0.4980\n",
      "Epoch 9/40\n",
      "4982/4982 [==============================] - 1s 172us/step - loss: 1.6698 - accuracy: 0.5221 - val_loss: 1.7535 - val_accuracy: 0.5185\n",
      "Epoch 10/40\n",
      "4982/4982 [==============================] - 1s 179us/step - loss: 1.6057 - accuracy: 0.5580 - val_loss: 1.6999 - val_accuracy: 0.5595\n",
      "Epoch 11/40\n",
      "4982/4982 [==============================] - 1s 172us/step - loss: 1.5423 - accuracy: 0.6068 - val_loss: 1.6475 - val_accuracy: 0.5982\n",
      "Epoch 12/40\n",
      "4982/4982 [==============================] - 1s 175us/step - loss: 1.4756 - accuracy: 0.6429 - val_loss: 1.5975 - val_accuracy: 0.6162\n",
      "Epoch 13/40\n",
      "4982/4982 [==============================] - 1s 175us/step - loss: 1.4163 - accuracy: 0.6632 - val_loss: 1.5505 - val_accuracy: 0.6320\n",
      "Epoch 14/40\n",
      "4982/4982 [==============================] - 1s 189us/step - loss: 1.3586 - accuracy: 0.6829 - val_loss: 1.5066 - val_accuracy: 0.6478\n",
      "Epoch 15/40\n",
      "4982/4982 [==============================] - 1s 195us/step - loss: 1.3029 - accuracy: 0.6929 - val_loss: 1.4666 - val_accuracy: 0.6497\n",
      "Epoch 16/40\n",
      "4982/4982 [==============================] - 1s 196us/step - loss: 1.2503 - accuracy: 0.7017 - val_loss: 1.4332 - val_accuracy: 0.6585\n",
      "Epoch 17/40\n",
      "4982/4982 [==============================] - 1s 178us/step - loss: 1.2056 - accuracy: 0.7124 - val_loss: 1.4023 - val_accuracy: 0.6640\n",
      "Epoch 18/40\n",
      "4982/4982 [==============================] - 1s 173us/step - loss: 1.1642 - accuracy: 0.7188 - val_loss: 1.3732 - val_accuracy: 0.6680\n",
      "Epoch 19/40\n",
      "4982/4982 [==============================] - 1s 170us/step - loss: 1.1227 - accuracy: 0.7272 - val_loss: 1.3486 - val_accuracy: 0.6722\n",
      "Epoch 20/40\n",
      "4982/4982 [==============================] - 1s 189us/step - loss: 1.0850 - accuracy: 0.7342 - val_loss: 1.3243 - val_accuracy: 0.6790\n",
      "Epoch 21/40\n",
      "4982/4982 [==============================] - 1s 196us/step - loss: 1.0508 - accuracy: 0.7407 - val_loss: 1.3041 - val_accuracy: 0.6812\n",
      "Epoch 22/40\n",
      "4982/4982 [==============================] - 1s 186us/step - loss: 1.0168 - accuracy: 0.7501 - val_loss: 1.2860 - val_accuracy: 0.6858\n",
      "Epoch 23/40\n",
      "4982/4982 [==============================] - 1s 190us/step - loss: 0.9881 - accuracy: 0.7563 - val_loss: 1.2689 - val_accuracy: 0.6905\n",
      "Epoch 24/40\n",
      "4982/4982 [==============================] - 1s 174us/step - loss: 0.9547 - accuracy: 0.7692 - val_loss: 1.2517 - val_accuracy: 0.6948\n",
      "Epoch 25/40\n",
      "4982/4982 [==============================] - 1s 179us/step - loss: 0.9255 - accuracy: 0.7780 - val_loss: 1.2360 - val_accuracy: 0.6990\n",
      "Epoch 26/40\n",
      "4982/4982 [==============================] - 1s 178us/step - loss: 0.8983 - accuracy: 0.7826 - val_loss: 1.2222 - val_accuracy: 0.7045\n",
      "Epoch 27/40\n",
      "4982/4982 [==============================] - 1s 179us/step - loss: 0.8701 - accuracy: 0.7886 - val_loss: 1.2095 - val_accuracy: 0.7085\n",
      "Epoch 28/40\n",
      "4982/4982 [==============================] - 1s 185us/step - loss: 0.8487 - accuracy: 0.7939 - val_loss: 1.1983 - val_accuracy: 0.7115\n",
      "Epoch 29/40\n",
      "4982/4982 [==============================] - 1s 183us/step - loss: 0.8194 - accuracy: 0.8015 - val_loss: 1.1862 - val_accuracy: 0.7145\n",
      "Epoch 30/40\n",
      "4982/4982 [==============================] - 1s 193us/step - loss: 0.8001 - accuracy: 0.8067 - val_loss: 1.1771 - val_accuracy: 0.7193\n",
      "Epoch 31/40\n",
      "4982/4982 [==============================] - 1s 178us/step - loss: 0.7731 - accuracy: 0.8121 - val_loss: 1.1651 - val_accuracy: 0.7237\n",
      "Epoch 32/40\n",
      "4982/4982 [==============================] - 1s 179us/step - loss: 0.7506 - accuracy: 0.8159 - val_loss: 1.1591 - val_accuracy: 0.7255\n",
      "Epoch 33/40\n",
      "4982/4982 [==============================] - 1s 173us/step - loss: 0.7297 - accuracy: 0.8214 - val_loss: 1.1459 - val_accuracy: 0.7275\n",
      "Epoch 34/40\n",
      "4982/4982 [==============================] - 1s 172us/step - loss: 0.7082 - accuracy: 0.8258 - val_loss: 1.1373 - val_accuracy: 0.7278\n",
      "Epoch 35/40\n",
      "4982/4982 [==============================] - 1s 175us/step - loss: 0.6859 - accuracy: 0.8318 - val_loss: 1.1320 - val_accuracy: 0.7280\n",
      "Epoch 36/40\n",
      "4982/4982 [==============================] - 1s 175us/step - loss: 0.6665 - accuracy: 0.8360 - val_loss: 1.1244 - val_accuracy: 0.7320\n",
      "Epoch 37/40\n",
      "4982/4982 [==============================] - 1s 174us/step - loss: 0.6444 - accuracy: 0.8416 - val_loss: 1.1178 - val_accuracy: 0.7345\n",
      "Epoch 38/40\n",
      "4982/4982 [==============================] - 1s 180us/step - loss: 0.6277 - accuracy: 0.8452 - val_loss: 1.1115 - val_accuracy: 0.7362\n",
      "Epoch 39/40\n",
      "4982/4982 [==============================] - 1s 183us/step - loss: 0.6067 - accuracy: 0.8539 - val_loss: 1.1053 - val_accuracy: 0.7370\n",
      "Epoch 40/40\n",
      "4982/4982 [==============================] - 1s 178us/step - loss: 0.5897 - accuracy: 0.8549 - val_loss: 1.1019 - val_accuracy: 0.7408\n"
     ]
    }
   ],
   "source": [
    "history_embed = model_embed.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 40,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 13us/step\n",
      "[1.1147394734414051, 0.7324131727218628]\n"
     ]
    }
   ],
   "source": [
    "results = model_embed.evaluate(test_data, y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se alcanza un accuracy de 73.24% en los datos de test, que son datos completamente desconocidos por lo tanto es un resultado aceptable.**\n",
    "\n",
    "A continuación se realizan pruebas con otras arquitecturas utilizando embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 250)         12250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 46)                11546     \n",
      "=================================================================\n",
      "Total params: 246,546\n",
      "Trainable params: 246,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Arquitectura de red convolucional de 1D que pueda reconocer \n",
    "#los PADS en los embeddings y pueda entrenarse adecuadamente\n",
    "\n",
    "vocab_size = max_features\n",
    "#Filtros de convolución y tamaño de kernel de recorrido en los\n",
    "#embeddings, se agregan capas de dropout  y al final una capa\n",
    "#Dense (Además de la final de clasificación) que permita simplificar\n",
    "#las salidas de la capa de convolución\n",
    "\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(vocab_size, 16))\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Conv1D(filters,\n",
    "                    kernel_size,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    strides=1))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(250, activation=tf.nn.relu))\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Dense(46, activation=tf.nn.sigmoid))\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\NWUSER\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4982 samples, validate on 4000 samples\n",
      "Epoch 1/6\n",
      "4982/4982 [==============================] - 2s 358us/step - loss: 2.2278 - accuracy: 0.3695 - val_loss: 1.8356 - val_accuracy: 0.4950\n",
      "Epoch 2/6\n",
      "4982/4982 [==============================] - 2s 322us/step - loss: 1.6244 - accuracy: 0.5813 - val_loss: 1.5480 - val_accuracy: 0.6325\n",
      "Epoch 3/6\n",
      "4982/4982 [==============================] - 2s 314us/step - loss: 1.3452 - accuracy: 0.6712 - val_loss: 1.4096 - val_accuracy: 0.6660\n",
      "Epoch 4/6\n",
      "4982/4982 [==============================] - 2s 306us/step - loss: 1.1439 - accuracy: 0.7077 - val_loss: 1.3427 - val_accuracy: 0.6790\n",
      "Epoch 5/6\n",
      "4982/4982 [==============================] - 2s 321us/step - loss: 0.9438 - accuracy: 0.7551 - val_loss: 1.3235 - val_accuracy: 0.7032\n",
      "Epoch 6/6\n",
      "4982/4982 [==============================] - 2s 314us/step - loss: 0.7740 - accuracy: 0.7941 - val_loss: 1.3420 - val_accuracy: 0.7020\n"
     ]
    }
   ],
   "source": [
    "history_cnn = model_cnn.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 6, #Se limita a 6 épocas por regularización con Early Stopping\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 109us/step\n",
      "[1.3155283704997172, 0.6932324171066284]\n"
     ]
    }
   ],
   "source": [
    "results = model_cnn.evaluate(test_data, y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La red convolucional alcanza un accuracy de 69.32%, sigue siendo adecuado pero es considerablemente menor que la red de embeddings simple, pero no se entrenan más épocas por la tendencia a caer en overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32)                18560     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                1518      \n",
      "=================================================================\n",
      "Total params: 1,300,078\n",
      "Trainable params: 1,300,078\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Se construye una red  bidireccional simple que reciba los enbeddings\n",
    "model_rnn =  Sequential()\n",
    "model_rnn.add(Embedding(max_features, 128))\n",
    "model_rnn.add(Bidirectional(LSTM(16)))\n",
    "model_rnn.add(Dropout(0.5))\n",
    "model_rnn.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\NWUSER\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4982 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "4982/4982 [==============================] - 23s 5ms/step - loss: 2.6900 - accuracy: 0.3448 - val_loss: 2.2527 - val_accuracy: 0.3483\n",
      "Epoch 2/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 2.1300 - accuracy: 0.3743 - val_loss: 2.0048 - val_accuracy: 0.4132\n",
      "Epoch 3/20\n",
      "4982/4982 [==============================] - 23s 5ms/step - loss: 1.9219 - accuracy: 0.4255 - val_loss: 1.8992 - val_accuracy: 0.4340\n",
      "Epoch 4/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.7748 - accuracy: 0.4558 - val_loss: 1.8560 - val_accuracy: 0.4428\n",
      "Epoch 5/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.6236 - accuracy: 0.4920 - val_loss: 1.6901 - val_accuracy: 0.4608\n",
      "Epoch 6/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.4396 - accuracy: 0.5684 - val_loss: 1.5917 - val_accuracy: 0.6068\n",
      "Epoch 7/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.3249 - accuracy: 0.6451 - val_loss: 1.5196 - val_accuracy: 0.6292\n",
      "Epoch 8/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.1825 - accuracy: 0.6764 - val_loss: 1.5219 - val_accuracy: 0.6255\n",
      "Epoch 9/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.1170 - accuracy: 0.7001 - val_loss: 1.5158 - val_accuracy: 0.6300\n",
      "Epoch 10/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 1.0374 - accuracy: 0.7198 - val_loss: 1.5325 - val_accuracy: 0.6357\n",
      "Epoch 11/20\n",
      "4982/4982 [==============================] - 21s 4ms/step - loss: 0.9807 - accuracy: 0.7365 - val_loss: 1.5064 - val_accuracy: 0.6438\n",
      "Epoch 12/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.9249 - accuracy: 0.7591 - val_loss: 1.5059 - val_accuracy: 0.6545\n",
      "Epoch 13/20\n",
      "4982/4982 [==============================] - 21s 4ms/step - loss: 0.8728 - accuracy: 0.7744 - val_loss: 1.4975 - val_accuracy: 0.6547\n",
      "Epoch 14/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.8262 - accuracy: 0.7908 - val_loss: 1.5006 - val_accuracy: 0.6622\n",
      "Epoch 15/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.7755 - accuracy: 0.8055 - val_loss: 1.5026 - val_accuracy: 0.6595\n",
      "Epoch 16/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.7248 - accuracy: 0.8224 - val_loss: 1.5171 - val_accuracy: 0.6702\n",
      "Epoch 17/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.7002 - accuracy: 0.8202 - val_loss: 1.4849 - val_accuracy: 0.6760\n",
      "Epoch 18/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.6586 - accuracy: 0.8334 - val_loss: 1.5178 - val_accuracy: 0.6752\n",
      "Epoch 19/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.6339 - accuracy: 0.8394 - val_loss: 1.4877 - val_accuracy: 0.6800\n",
      "Epoch 20/20\n",
      "4982/4982 [==============================] - 22s 4ms/step - loss: 0.5923 - accuracy: 0.8565 - val_loss: 1.5147 - val_accuracy: 0.6820\n"
     ]
    }
   ],
   "source": [
    "history_rnn = model_rnn.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 20, ##Se limita a 20 épocas por regularización con Early Stopping\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 185us/step\n",
      "[1.6228543833123714, 0.6571683287620544]\n"
     ]
    }
   ],
   "source": [
    "results = model_rnn.evaluate(test_data, y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El accuracy de la red recurrente es del 65.71% que es ligeramente menor al de la red convolucional pero el tiempo que toma el entrenamiento de esta red es considerablemente mayor a las anteriores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Actividad 3 - Parte 1",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
